# ETL Pipeline - 20250904_163115

## Files Generated
- `etl_pipeline_20250904_163115.py` - Python ETL script
- `etl_pipeline_20250904_163115.ipynb` - Jupyter notebook with documentation
- `etl_pipeline_20250904_163115_README.md` - This README file

## Configuration
YAML: YAML config with keys: metadata, source, target...

## Validation Summary
- Passed: 8/9 checks
- Critical checks: SparkSession, Delta Lake, Security

## Test Summary
- Passed: 5/6 tests

## Running the Pipeline

### Prerequisites
1. Set environment variables:
   ```bash
   set ORACLE_USERNAME=your_username
   set ORACLE_PASSWORD=your_password
   set ORACLE_HOST=your_host
   set ORACLE_PORT=1521
   set ORACLE_SERVICE=your_service
   set DELTA_LAKE_LOCATION=C:\path\to\delta
   ```

2. Install dependencies:
   ```bash
   pip install pyspark delta-spark
   ```

3. Run the pipeline:
   ```bash
   spark-submit etl_pipeline_20250904_163115.py
   ```

## Notes
- This code was auto-generated by the ETL Pipeline Generator
- Review and test thoroughly before production use
- Modify connection parameters as needed for your environment
- This version includes Windows UTF-8 compatibility fixes
